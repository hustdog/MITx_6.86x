{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the hinge loss on a single data point given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing the given data point.\n",
    "        label - A real valued number, the correct classification of the data\n",
    "            point.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given data point and parameters.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    loss = max(1- (np.dot(theta, feature_vector) + theta_0) * label, 0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the total hinge loss on a set of data given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given dataset and parameters. This number should be the average hinge\n",
    "    loss across all of the points in the feature matrix.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    loss = np.maximum(1 - (np.dot(theta, feature_matrix.T,) + theta_0) * labels, 0)\n",
    "    return np.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the perceptron algorithm.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        current_theta - The current theta being used by the perceptron\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the perceptron\n",
    "            algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    if label*(np.dot(current_theta, feature_vector.T) + current_theta_0) <= 1e-8:\n",
    "        current_theta = current_theta + label * feature_vector\n",
    "        current_theta_0 = current_theta_0 + label\n",
    "    return(current_theta,current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta, the linear classification parameter, after T iterations through the\n",
    "    feature matrix and the second element is a real number with the value of\n",
    "    theta_0, the offset classification parameter, after T iterations through\n",
    "    the feature matrix.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    current_theta = np.zeros(feature_matrix.shape[1])\n",
    "    current_theta_0 = 0.0\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            # Your code here\n",
    "            current_theta, current_theta_0 = perceptron_single_step_update(feature_matrix[i,:], labels[i], current_theta, current_theta_0)\n",
    "    return (current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the average theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the average theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "\n",
    "    Hint: It is difficult to keep a running average; however, it is simple to\n",
    "    find a sum and divide.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    current_theta = np.zeros(feature_matrix.shape[1])\n",
    "    current_theta_0 = 0.0\n",
    "    current_theta_sum = np.zeros(feature_matrix.shape[1])\n",
    "    current_theta_0_sum = 0.0\n",
    "\n",
    "    n = feature_matrix.shape[0]\n",
    "\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            current_theta, current_theta_0 = perceptron_single_step_update(feature_matrix[i,:], labels[i], current_theta, current_theta_0)\n",
    "            current_theta_sum += current_theta\n",
    "            current_theta_0_sum += current_theta_0\n",
    "    theta_avg = current_theta_sum/(n*T)\n",
    "    theta_0_avg = current_theta_0_sum/(n*T)\n",
    "    return (theta_avg, theta_0_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        L,\n",
    "        eta,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the Pegasos algorithm\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        L - The lamba value being used to update the parameters.\n",
    "        eta - Learning rate to update parameters.\n",
    "        current_theta - The current theta being used by the Pegasos\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the\n",
    "            Pegasos algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    if label*(np.dot(current_theta, feature_vector.T) + current_theta_0) <= 1:\n",
    "          current_theta = (1 - eta*L) * current_theta + eta * label * feature_vector\n",
    "          current_theta_0 = current_theta_0 + eta * label\n",
    "    else:\n",
    "          current_theta = (1 - eta*L) * current_theta\n",
    "\n",
    "    return(current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(feature_matrix, labels, T, L):\n",
    "    \"\"\"\n",
    "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    For each update, set learning rate = 1/sqrt(t),\n",
    "    where t is a counter for the number of updates performed so far (between 1\n",
    "    and nT inclusive).\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the algorithm\n",
    "            should iterate through the feature matrix.\n",
    "        L - The lamba value being used to update the Pegasos\n",
    "            algorithm parameters.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    c = 1\n",
    "    current_theta = np.zeros(feature_matrix.shape[1])\n",
    "    current_theta_0 = 0.0\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            eta = 1 / np.sqrt(c)\n",
    "            c += 1\n",
    "            # Your code here\n",
    "            current_theta, current_theta_0 = pegasos_single_step_update(feature_matrix[i,:], labels[i], L, eta, current_theta, current_theta_0)\n",
    "    return (current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
